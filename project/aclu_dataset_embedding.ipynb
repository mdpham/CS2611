{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426d18f5-983a-40e8-b78a-24698310eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary to include the project directory into system paths\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc18f2d-bc1a-4ef7-85b9-c97dceaaab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can import from project directory\n",
    "from project.src.data_classes import (\n",
    "    Opinion,\n",
    "    ProjectUtils,\n",
    "    gender_words,\n",
    "    charlesworth_2021_words\n",
    ")\n",
    "# \n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from wefe.query import Query\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a61096d-2d4c-4559-a465-2015449651f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of opinions: 92\n",
      "Number of unique cases: 37\n",
      "case_name\n",
      "Harris v. McRae                                                      4\n",
      "Thornburgh v. American College of Obstetricians and Gynecologists    4\n",
      "Craig v. Boren                                                       4\n",
      "Orr v. Orr                                                           4\n",
      "Nevada Department of Human Resources v. Hibbs                        4\n",
      "Griswold v. Connecticut                                              4\n",
      "Green v. Brennan                                                     3\n",
      "United States v. Virginia                                            3\n",
      "Taylor v. Louisiana                                                  3\n",
      "Stanton v. Stanton                                                   3\n",
      "Rust v. Sullivan                                                     3\n",
      "Rostker v. Goldberg                                                  3\n",
      "Roe v. Wade                                                          3\n",
      "Kahn v. Shevin                                                       3\n",
      "AT&T Corp. v. Hulteen                                                3\n",
      "Fisher v. University of Texas at Austin                              3\n",
      "Eisenstadt v. Baird                                                  3\n",
      "Bowen v. Kendrick                                                    3\n",
      "Doe v. Bolton                                                        3\n",
      "Geduldig v. Aiello                                                   2\n",
      "Frontiero v. Richardson                                              2\n",
      "United States v. Vuitch                                              2\n",
      "Bigelow v. Virginia                                                  2\n",
      "County of Washington v. Gunther                                      2\n",
      "Roberts v. United States Jaycees                                     2\n",
      "Pennsylvania State Police v. Suders                                  2\n",
      "Duren v. Missouri                                                    2\n",
      "Nashville Gas Co. v. Satty                                           2\n",
      "Hishon v. King & Spalding                                            2\n",
      "Webster v. Reproductive Health Services                              2\n",
      "Reed v. Reed                                                         1\n",
      "Dothard v. Rawlinson                                                 1\n",
      "Department of Housing and Urban Development v. Rucker                1\n",
      "Sessions v. Morales-Santana                                          1\n",
      "Corning Glass Works v. Brennan                                       1\n",
      "Califano v. Westcott                                                 1\n",
      "Bellotti v. Baird                                                    1\n",
      "dtype: int64\n",
      "----\n",
      "category\n",
      "majority             37\n",
      "dissenting           24\n",
      "concurring           19\n",
      "second_dissenting    10\n",
      "per_curiam            2\n",
      "dtype: int64\n",
      "----\n",
      "Number of unique justices: 21\n",
      "author_name\n",
      "Justice Rehnquist    17\n",
      "Justice Blackmun     10\n",
      "Justice Brennan       9\n",
      "Justice White         8\n",
      "Justice Burger        5\n",
      "Justice Ginsburg      5\n",
      "Justice Stewart       5\n",
      "Justice Powell        4\n",
      "Justice Stevens       4\n",
      "Justice O'Connor      3\n",
      "Justice Douglas       3\n",
      "Justice Marshall      3\n",
      "Justice Scalia        3\n",
      "Justice Souter        2\n",
      "Justice Thomas        2\n",
      "per_curiam            2\n",
      "Justice Black         2\n",
      "Justice Kennedy       2\n",
      "Justice Sotomayor     1\n",
      "Justice Goldberg      1\n",
      "Justice Alito         1\n",
      "dtype: int64\n",
      "----\n",
      "scdb_decision_direction\n",
      "2.0    23\n",
      "1.0    14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "aclu_opinions = pd.read_csv('aclu_opinions.csv').sort_values('year_filed')\n",
    "ProjectUtils.summarize_opinions_metadata(aclu_opinions)\n",
    "# ProjectUtils.plot_corpora_scatter(aclu_opinions, type_token='type_count')\n",
    "# ProjectUtils.plot_corpora_scatter(aclu_opinions, type_token='token_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fea9abe-2acf-4db5-bf30-b71b01a07b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only interested in 'Roe v. Wade' decision\n",
    "# roe_wade_opinions = aclu_opinions[aclu_opinions['case_name'] == 'Roe v. Wade']\n",
    "\n",
    "# ... or over time\n",
    "# Only interested in 'Second wave feminism' i.e. 1960-1980\n",
    "# opinions_second_wave = aclu_opinions[aclu_opinions['year_filed'].between(1962, 1982)]\n",
    "\n",
    "# ProjectUtils.summarize_opinions_metadata(opinions_second_wave)\n",
    "# ProjectUtils.plot_corpora_scatter(opinions_second_wave, type_token='type_count')\n",
    "# ProjectUtils.plot_corpora_scatter(opinions_second_wave, type_token='token_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f240b79-67b0-4e17-90f7-f527208199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_words_male = charlesworth_2021_words['malemax']\n",
    "target_words_female = charlesworth_2021_words['femalemax']\n",
    "attribute_words_home = charlesworth_2021_words['homemax']\n",
    "attribute_words_work = charlesworth_2021_words['workmax']\n",
    "attribute_words_good = charlesworth_2021_words['good']\n",
    "attribute_words_bad = charlesworth_2021_words['bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "106abe90-c89f-400f-b5c7-6edb95b77609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# opinions = roe_wade_opinions['text'].values\n",
    "\n",
    "# opinions = opinions_second_wave['text'].values\n",
    "\n",
    "# pregnancy_cases = [\"Griswold v. Connecticut\", \"Eisenstadt v. Baird\", \"Roe v. Wade\", \"Doe v. Bolton\", \"Geduldig v. Aiello\", \"Bellotti v. Baird\"]\n",
    "# opinions = aclu_opinions.loc[aclu_opinions['case_name'].isin(pregnancy_cases)]['text'].values\n",
    "\n",
    "# opinions = aclu_opinions['text'].values\n",
    "\n",
    "# Liberal\n",
    "opinions = aclu_opinions.loc[\n",
    "    (aclu_opinions['scdb_decision_direction'].isin([1.])) &\n",
    "    (aclu_opinions['category']=='majority')\n",
    "]['text'].values\n",
    "\n",
    "# len(text)\n",
    "# tokenized opinion text\n",
    "# print(opinions)\n",
    "print(len(opinions))\n",
    "ugram = Counter()\n",
    "bigram = Counter()\n",
    "for i, text in enumerate(opinions):\n",
    "    print(i)\n",
    "    clean_text = ProjectUtils.clean_text(text)\n",
    "    ugram, bigram = ProjectUtils.count_grams(clean_text, ugram, bigram)\n",
    "    # print(ugram.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee182847-38e7-4ecf-a31a-bae12ff9e6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cdf8ddd-68fb-4d1d-9578-0f3887c40812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male target word counts\n",
      "\this 36\n",
      "\tmen 31\n",
      "\the 22\n",
      "\tmale 21\n",
      "\thim 4\n",
      "\tman 3\n",
      "\tbrother 2\n",
      "\tking 2\n",
      "\tfather 1\n",
      "\tson 1\n",
      "Female target word counts\n",
      "\twomen 187\n",
      "\ther 69\n",
      "\twoman 58\n",
      "\tshe 49\n",
      "\tmother 18\n",
      "\tfemale 11\n",
      "\therself 7\n",
      "\tdaughter 1\n",
      "Work attribute word counts\n",
      "\tjob 23\n",
      "\tbusiness 16\n",
      "\texecutive 12\n",
      "\toffice 11\n",
      "\tcorporation 11\n",
      "\twork 9\n",
      "\tprofessional 6\n",
      "\thiring 6\n",
      "\thire 2\n",
      "\tmoney 2\n",
      "\tsalary 1\n",
      "\tcorporate 1\n",
      "Home attribute word counts\n",
      "\tfamily 66\n",
      "\thouse 18\n",
      "\tchildren 15\n",
      "\trelative 8\n",
      "\tparent 3\n",
      "\tmarriage 2\n",
      "\tcousins 2\n",
      "\thome 2\n",
      "Good attribute word counts\n",
      "\tgood 18\n",
      "Bad attribute word counts\n",
      "\tabuse 4\n",
      "\tstress 3\n",
      "\tdeath 1\n",
      "\tbad 1\n"
     ]
    }
   ],
   "source": [
    "male_ugram = Counter(dict([(k,v) for k,v in ugram.items() if k in target_words_male]))\n",
    "female_ugram = Counter(dict([(k,v) for k,v in ugram.items() if k in target_words_female]))\n",
    "print('Male target word counts')\n",
    "for (w,c) in male_ugram.most_common(20):\n",
    "    print('\\t{} {}'.format(w, c))\n",
    "print('Female target word counts')\n",
    "for (w,c) in female_ugram.most_common(20):\n",
    "    print('\\t{} {}'.format(w, c))\n",
    "    \n",
    "work_ugram = Counter(dict([(k,v) for k,v in ugram.items() if k in attribute_words_work]))\n",
    "home_ugram = Counter(dict([(k,v) for k,v in ugram.items() if k in attribute_words_home]))\n",
    "print('Work attribute word counts')\n",
    "for (w,c) in work_ugram.most_common(20):\n",
    "    print('\\t{} {}'.format(w, c))\n",
    "print('Home attribute word counts')\n",
    "for (w,c) in home_ugram.most_common(20):\n",
    "    print('\\t{} {}'.format(w, c))\n",
    "    \n",
    "good_ugram = Counter(dict([(k,v) for k,v in ugram.items() if k in attribute_words_good]))\n",
    "bad_ugram = Counter(dict([(k,v) for k,v in ugram.items() if k in attribute_words_bad]))\n",
    "print('Good attribute word counts')\n",
    "for (w,c) in good_ugram.most_common(20):\n",
    "    print('\\t{} {}'.format(w, c))\n",
    "print('Bad attribute word counts')\n",
    "for (w,c) in bad_ugram.most_common(20):\n",
    "    print('\\t{} {}'.format(w, c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be0a201c-becc-4411-a3be-49be778d8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProjectUtils.plot_ngram_barchart(ugram)\n",
    "# ProjectUtils.plot_ngram_barchart(bigram)\n",
    "# ProjectUtils.plot_unigram_wordcloud(ugram)\n",
    "# ProjectUtils.most_common_unigram_heatmap(ugram, bigram)\n",
    "# ProjectUtils.most_common_bigram_heatmap(bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683bf812-639d-4a25-a891-a698c28604a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abf189e2-f456-4371-9b97-7669fb702594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should only need to do this once per weat test condition\n",
    "ppmi, cooccurence, x2i, i2x = ProjectUtils.model_matrices(ugram, bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3604f36f-b490-4052-a8a0-c00fd3dc95cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csc.csc_matrix'>\n",
      "U shape (5601, 500)\n",
      "S shape (500,)\n",
      "VT shape (500, 5601)\n"
     ]
    }
   ],
   "source": [
    "svd = ProjectUtils.model_svd(ppmi, k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0228f29-2c58-4c9f-90c8-c784b2d7d6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job, 23\n",
      " issuewhether, 0.951\n",
      " jobrelated, 0.951\n",
      " ironic, 0.920\n",
      " jobrelatedness, 0.890\n",
      " invisible, 0.879\n",
      " \n",
      "----------\n",
      "business, 16\n",
      " button, 0.587\n",
      " buffers, 0.583\n",
      " bylaws, 0.568\n",
      " campaign, 0.511\n",
      " broadened, 0.483\n",
      " \n",
      "----------\n",
      "executive, 12\n",
      " expand, 0.677\n",
      " exceeded, 0.562\n",
      " exempt, 0.505\n",
      " exempting, 0.544\n",
      " eventual, 0.488\n",
      " \n",
      "----------\n",
      "office, 11\n",
      " offering, 0.581\n",
      " obligations, 0.631\n",
      " officer, 0.563\n",
      " ones, 0.608\n",
      " okla, 0.519\n",
      " \n",
      "----------\n",
      "corporation, 11\n",
      " continuity, 0.600\n",
      " contra, 0.634\n",
      " controls, 0.650\n",
      " credit, 0.556\n",
      " contemporary, 0.480\n",
      " \n",
      "----------\n",
      "work, 9\n",
      " workforce, 0.894\n",
      " workmanship, 0.886\n",
      " womenthat, 0.891\n",
      " worse, 0.871\n",
      " words, 0.851\n",
      " \n",
      "----------\n",
      "professional, 6\n",
      " protections, 0.621\n",
      " proposals, 0.641\n",
      " proclamation, 0.640\n",
      " print, 0.601\n",
      " profession, 0.594\n",
      " \n",
      "----------\n",
      "hiring, 6\n",
      " hired, 0.829\n",
      " holds, 0.779\n",
      " holdingthat, 0.795\n",
      " heterosexual, 0.761\n",
      " hire, 0.799\n",
      " \n",
      "----------\n",
      "hire, 2\n",
      " holdingthat, 0.879\n",
      " holds, 0.852\n",
      " heterosexual, 0.985\n",
      " height, 0.861\n",
      " hired, 0.978\n",
      " \n",
      "----------\n",
      "money, 2\n",
      " mislead, 0.577\n",
      " methods, 0.868\n",
      " mechanism, 0.616\n",
      " monies, 0.597\n",
      " monitored, 0.559\n",
      " \n",
      "----------\n",
      "family, 66\n",
      " farm, 0.718\n",
      " extreme, 0.693\n",
      " familyplanning, 0.781\n",
      " facial, 0.717\n",
      " fascism, 0.664\n",
      " \n",
      "----------\n",
      "house, 18\n",
      " ignore, 0.895\n",
      " hope, 0.964\n",
      " holt, 0.930\n",
      " ignored, 0.839\n",
      " houses, 0.834\n",
      " \n",
      "----------\n",
      "children, 15\n",
      " child, 0.752\n",
      " childbirth, 0.571\n",
      " chooses, 0.543\n",
      " chemehuevi, 0.522\n",
      " caterpillar, 0.437\n",
      " \n",
      "----------\n",
      "relative, 8\n",
      " relies, 0.727\n",
      " rehnquist, 0.514\n",
      " relevant, 0.552\n",
      " relatives, 0.526\n",
      " regular, 0.520\n",
      " \n",
      "----------\n",
      "parent, 3\n",
      " painted, 0.995\n",
      " parental, 0.992\n",
      " parentsid, 0.785\n",
      " parentalconsent, 0.933\n",
      " parents, 0.759\n",
      " \n",
      "----------\n",
      "marriage, 2\n",
      " mcclure, 0.552\n",
      " mark, 0.994\n",
      " mathews, 0.941\n",
      " matching, 0.525\n",
      " mccrary, 0.512\n",
      " \n",
      "----------\n",
      "cousins, 2\n",
      " creed, 0.961\n",
      " counterexample, 0.956\n",
      " courses, 0.998\n",
      " correlative, 0.744\n",
      " corsi, 0.855\n",
      " \n",
      "----------\n",
      "home, 2\n",
      " hop, 0.976\n",
      " holistic, 0.998\n",
      " hopwood, 0.964\n",
      " hispanic, 0.928\n",
      " ically, 0.877\n",
      " \n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "U = svd['U']\n",
    "\n",
    "most_common_gender_words = dict(male_ugram.most_common(10) + female_ugram.most_common(10)).keys()\n",
    "most_common_words = dict(ugram.most_common(20)).keys()\n",
    "most_common_attribute_words = dict(work_ugram.most_common(10) + home_ugram.most_common(10)).keys()\n",
    "\n",
    "k = 5\n",
    "# for x in most_common_gender_words:\n",
    "# for x in most_common_words:\n",
    "for x in most_common_attribute_words:\n",
    "    dd = np.dot(U, U[x2i[x]]) # Cosine similarity for this unigram against all others.\n",
    "    s = ''\n",
    "    # Compile the list of nearest neighbor descriptions.\n",
    "    # Argpartition is faster than argsort and meets our needs.\n",
    "    for i in np.argpartition(-1 * dd, k + 1)[:k + 1]:\n",
    "        if i2x[i] == x: continue\n",
    "        s += '%s, %.3lf\\n ' % (i2x[i], dd[i])\n",
    "    print('%s, %d\\n %s' % (x, ugram[x], s))\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e1708a5-f7b2-4bb0-938e-3d1aa56f9813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1d40601f0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kv = ProjectUtils.svd_keyed_vectors(svd, x2i, k=500)\n",
    "model_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "475566cc-25cf-478d-814a-70e1bf10784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_name': 'Female terms and Male Terms wrt Home terms and Work terms', 'result': -0.30621195326481637, 'weat': -0.30621195326481637, 'effect_size': -1.0497267291079782, 'p_value': 0.9859014098590141}\n",
      "{'query_name': 'Female terms and Male Terms wrt Home terms and Work terms', 'result': -0.30621195326481637, 'weat': -0.30621195326481637, 'effect_size': -1.0497267291079782, 'p_value': 0.9859014098590141}\n"
     ]
    }
   ],
   "source": [
    "gender_query = Query(\n",
    "    target_sets=[\n",
    "        charlesworth_2021_words['femalemax'],\n",
    "        charlesworth_2021_words['malemax'],\n",
    "    ],\n",
    "    attribute_sets=[\n",
    "        charlesworth_2021_words['homemax'],\n",
    "        charlesworth_2021_words['workmax'],\n",
    "    ],\n",
    "    target_sets_names=[\"Female terms\", \"Male Terms\"],\n",
    "    attribute_sets_names=[\"Home terms\", \"Work terms\"],\n",
    ")\n",
    "\n",
    "weat_results = ProjectUtils.kv_weat_test(model_kv, gender_query)\n",
    "print(weat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a20009e4-2ea7-4225-a726-68f932556121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_name': 'Female terms and Male Terms wrt Good terms and Bad terms', 'result': 0.06449852808145806, 'weat': 0.06449852808145806, 'effect_size': 0.2783498618501594, 'p_value': 0.2806719328067193}\n",
      "{'query_name': 'Female terms and Male Terms wrt Good terms and Bad terms', 'result': 0.06449852808145806, 'weat': 0.06449852808145806, 'effect_size': 0.2783498618501594, 'p_value': 0.2806719328067193}\n"
     ]
    }
   ],
   "source": [
    "moral_query = Query(\n",
    "    target_sets=[\n",
    "        charlesworth_2021_words['femalemax'],\n",
    "        charlesworth_2021_words['malemax'],\n",
    "    ],\n",
    "    attribute_sets=[\n",
    "        charlesworth_2021_words['good'],\n",
    "        charlesworth_2021_words['bad'],\n",
    "    ],\n",
    "    target_sets_names=[\"Female terms\", \"Male Terms\"],\n",
    "    attribute_sets_names=[\"Good terms\", \"Bad terms\"],\n",
    ")\n",
    "\n",
    "weat_results = ProjectUtils.kv_weat_test(model_kv, moral_query, lost_vocab_threshold=1.)\n",
    "print(weat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42adefe-337c-4567-99c0-3fe2b68150bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
